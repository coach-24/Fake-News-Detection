{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3b1bd941",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9974747474747475,\n",
       " 0.9979423868312757,\n",
       " 0.9969167523124358,\n",
       " 0.9974293059125964,\n",
       " ['              precision    recall  f1-score   support',\n",
       "  '',\n",
       "  '        Fake       1.00      1.00      1.00       973',\n",
       "  '        Real       1.00      1.00      1.00      1007',\n",
       "  '',\n",
       "  '    accuracy                           1.00      1980',\n",
       "  '   macro avg       1.00      1.00      1.00      1980',\n",
       "  'weighted avg       1.00      1.00      1.00      1980'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries again after code execution environment reset\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv(\"fake_and_real_news.csv\")\n",
    "\n",
    "# Drop null values\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "# Split into features and labels\n",
    "X = df[\"Text\"]\n",
    "y = df[\"label\"]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create pipeline with TF-IDF and Random Forest\n",
    "model_rf = make_pipeline(TfidfVectorizer(stop_words='english'), RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "\n",
    "# Train the model\n",
    "model_rf.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred_rf = model_rf.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
    "precision_rf = precision_score(y_test, y_pred_rf, pos_label='Fake')\n",
    "recall_rf = recall_score(y_test, y_pred_rf, pos_label='Fake')\n",
    "f1_rf = f1_score(y_test, y_pred_rf, pos_label='Fake')\n",
    "report_rf = classification_report(y_test, y_pred_rf)\n",
    "\n",
    "accuracy_rf, precision_rf, recall_rf, f1_rf, report_rf.splitlines()[:10]  # Show top part of classification report only\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
